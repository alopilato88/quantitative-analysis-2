---
title: "Clustered Data and the LMER Model"
format: 
  revealjs:
    theme: [default, theme-lecture-slides.scss] 
    css: styles-lecture-slides.css
    slide-number: true
execute:
  echo: true
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: load-packages
#| include: false
source("packages-lecture.R")
source("helper-functions-lecture.R")

```

## Overview for Today

Today we will be learning about: 

- The effects clustered designs can have on your statistical models
- The Linear Mixed-Effects Regression (LMER) Model 

## What are Clustered Data Structures? 

Clustered data structures occur when your data is nested within in a higher-level structure (a cluster):

- Employees nested within a team (team = cluster)
- Students nested within a classroom (classroom = cluster)
- Repeated measurements on an individual (individual = cluster)

## Our Data Example

```{r}
#| echo: false

set.seed(9547)

n1 <- 10
n2 <- 80
n <- n1 * n2

team_id <- rep(1:n2, each = n1)
b_context <- .50
b_within <- .30
b_between <- b_context + b_within 
z <- model.matrix(~ as.factor(team_id) - 1)
x <- 6 + rnorm(n, sd = 1) + z %*% rnorm(n2, sd = sqrt(.50))
x_rd <- round(as.numeric(x), 2)

data_ps <- 
  tibble::tibble(
    team_id,
    x_inc_lead = x_rd
  ) |>
  dplyr::group_by(
    team_id
  ) |>
  dplyr::mutate(
    x_inc_lead_gpm = mean(x_inc_lead)
  ) |>
  dplyr::ungroup() |>
  dplyr::mutate(
    x_inc_lead_gpc = x_inc_lead - x_inc_lead_gpm,
    y_psych_safe = 1 + b_within*x_inc_lead + b_context*x_inc_lead_gpm + rnorm(n, 1) + z%*%rnorm(n2, sd = sqrt(.25)),
    y_psych_safe = round(as.numeric(y_psych_safe), 2)
  ) |>
  dplyr::select(
    team_id, x_inc_lead, y_psych_safe
  )
```

You work for an organization that is interested in understanding how the inclusive behaviors of a team's leader impacts their team's perceptions of psychological safety---the shared belief that it is OK to take risks, speak up, or admit mistakes without fear of negative consequences. 

```{r}
#| echo: false

data_ps
```

## The Impact of Clustered Designs 

In our example, employees are clustered within a team leader. What impact could this have on the data we collect? Do you think that employees who report to the same leader are more similar than employees who report to a different leader? 

## When Data Are Not Independent 

Clustered data structures tend to violate the regression assumption of independent data. That is, to use regular linear regression we have to assume that we can not learn about person A's score on an outcome variable by looking at person B's score on that outcome variable.

Think about it this way: Are you more similar to your family members than you are a stranger?

## Visualizing Non-Independence 

```{r}
#| echo: false

set.seed(4)

n1 <- 30
n2 <- 3
n <- n1*n2
cluster <- rep(1:n2, each = n1)
z <- model.matrix(~as.factor(cluster) - 1)
x1 <- rnorm(n, sd = sqrt(2))
x2 <- rnorm(n, sd = 1) + z%*%rnorm(n2, sd = 1)
x3 <- rnorm(n, sd = sqrt(.05)) + z%*%rnorm(n2, sd = sqrt(1.95))

data_dep <- tibble::tibble(
  cluster = rep(cluster, 3),
  x = c(as.numeric(x1), as.numeric(x2), as.numeric(x3)),
  id = rep(c("No Violation", "Moderate Violation", "Strong Violation"), each = n)
) |>
  dplyr::mutate(
    id = factor(id, levels = c("No Violation", "Moderate Violation", "Strong Violation"))
  )

ggplot2::ggplot(
  data_dep,
  ggplot2::aes(x = as.factor(cluster), y = x)
) + 
  ggplot2::geom_point(shape = 21, fill = plot_fill, color = plot_color) + 
  ggplot2::facet_wrap(~ id) + 
  lecture_ggplot_theme_barplot + 
  ggplot2::labs(
    x = "Cluster Membership",
    y = "Outcome Variable"
  )
```

## Partitioning Variance into Within and Between-Clusters

Non-independence occurs when some of the total variance in our outcome variable is due to belonging to a given cluster or group. 
If we selected a person at random from Cluster A and a person at random from Cluster B, there score on an outcome variable will differ partly because they are different people (**Within-Cluster Variance**) and partly because they belong to different clusters (**Between-Cluster Variance**).

If there was no between-cluster difference, then the scores would only differ because we were looking at two different people. 

## Partitioning Variance into Within and Between-Clusters

The plot below shows the individual outcome scores by cluster (blue points), the cluster means for each cluster (red points), and the grand (or overall) mean (the blue line).

```{r}
#| echo: false
#| fig-align: center
data_dep_2 <- 
  data_dep |>
  dplyr::group_by(
    cluster, id
  ) |>
  dplyr::mutate(
    group_mean = mean(x)
  ) |>
  dplyr::group_by(
    id
  ) |>
  dplyr::mutate(
    grand_mean = mean(x)
  ) |>
  dplyr::ungroup()

data_group_mean <-
  data_dep_2 |>
  dplyr::select(
    id, cluster, group_mean
  ) |>
  dplyr::distinct()

data_grand_mean <- 
  data_dep_2 |>
  dplyr::select(
    id, grand_mean
  ) |>
  dplyr::distinct()

ggplot2::ggplot(
  data_dep_2,
  ggplot2::aes(x = as.factor(cluster), y = x)
) + 
  ggplot2::geom_point(shape = 21, fill = plot_fill, color = plot_color) + 
  ggplot2::facet_wrap(~ id) + 
  ggplot2::geom_point(
    data = data_group_mean,
    shape = 21, size = 3, fill = "red",
    ggplot2::aes(
      x = cluster, y = group_mean
    )
  ) + 
  ggplot2::geom_hline(
    data = data_grand_mean,
    size = 1.5,
    color = "blue",
    ggplot2::aes(yintercept = grand_mean)
  ) +
  lecture_ggplot_theme_barplot + 
  ggplot2::labs(
    x = "Cluster Membership",
    y = "Outcome Variable"
  )
```

## Quantifying Non-Independence with the ICC

The ICC or Intraclass Correlation Coefficient tells us how correlated two randomly selected scores from the same cluster are:

$$r_{1, 2}=\text{ICC}=\frac{\text{Between Cluster Variance}}{\text{Total Variance}}$$

## Quantifying Non-Independence with the ICC

```{r}
#| echo: false
data_dep_3 <- 
  data_dep_2 |>
  dplyr::mutate(
    icc = rep(c(0, .50, .98), each = n)
  ) |>
  dplyr::mutate(
    title = paste0(id, " - ", icc),
    id = factor(title, levels = c("No Violation - 0", "Moderate Violation - 0.5", "Strong Violation - 0.98"))
  ) 

data_group_mean <-
  data_dep_3 |>
  dplyr::summarize(
    group_mean = mean(x),
    .by = c(id, cluster)
  )

data_grand_mean <- 
  data_dep_3 |>
  dplyr::summarize(
    grand_mean = mean(x),
    .by = id
  )

ggplot2::ggplot(
  data_dep_3,
  ggplot2::aes(x = as.factor(cluster), y = x)
) + 
  ggplot2::geom_point(shape = 21, fill = plot_fill, color = plot_color) + 
  ggplot2::facet_wrap(~ id) + 
  ggplot2::geom_point(
    data = data_group_mean,
    shape = 21, size = 3, fill = "red",
    ggplot2::aes(
      x = cluster, y = group_mean
    )
  ) + 
  ggplot2::geom_hline(
    data = data_grand_mean,
    size = 1.5,
    color = "blue",
    ggplot2::aes(yintercept = grand_mean)
  ) +
  lecture_ggplot_theme_barplot + 
  ggplot2::labs(
    x = "Cluster Membership",
    y = "Outcome Variable"
  )
```

## Modeling Non-Independence with LMER Models

We need to use Linear Mixed-Effects Regression Models to model data when the independence data has been violated. 

LMER models are also known as: 

- Multilevel Models (MLM)
- Hierarchical Linear Models (HLM)
- Random Coefficient Models (RCM)

## The Unconditional Random-Intercept Model 

The LMER model without any predictors can be written as: 

$$\text{Level 1:} \space Y_{ij} = \beta_{0j} + r_{ij}$$
$$\text{Level 2:} \space \beta_{0j} = \gamma_{00} + u_{0j}$$

## Understanding the Unconditional Random-Intercept Model 

You can think of the unconditional model as a model that separates within-cluster variance from between-cluster variance. 

- $Y_{ij}$: The outcome for person i in cluster j. 
- $\beta_{0j}$: The intercept for cluster j---each cluster now gets its own intercept---the "random-intercept" 
- $\gamma_{00}$: The overall intercept (the grand mean of the outcome variable)
- $r_{ij}$: The within-cluster residual (level 1 error term) that captures the within-cluster variation
- $u_{0j}$: The between-cluster residual (level 2 error term) that captures the between-cluster variation

## Estimating the Unconditional Random-Intercept Model 

To estimate an LMER model, we will use the `lmer` function from the `lmerTest` package. The arguments you provide the `lmer` function are very similar to the ones you provide the `lm` function with one exception: `(1|team_id)`. 

`(1|team_id)` is the piece of the LMER formula that tells R what cluster a response belongs to.

```{r}
mod0 <- lmerTest::lmer(y_psych_safe ~ 1 + (1|team_id), data = data_ps)
```

## Interpreting the Results of an Unconditional Random-Intercept Model

```{r}
#| echo: false
summary(mod0)
```

## Visualizing the Results 

Each cluster gets its own line with a cluster-specific intercept. The variation you see between the intercepts is the between-group variance that we would like to model.

```{r}
#| echo: false 

set.seed(43)
mod0_ranef <- sample(ranef(mod0)$team_id[,1], size = 10) + summary(mod0)$coef[1]

data_uc_int <- 
  tibble::tibble(
    ranef = mod0_ranef
  )

ggplot2::ggplot(
  data = data_uc_int
) +
  ggplot2::geom_hline(
    ggplot2::aes(yintercept = ranef),
    color = plot_fill,
    size = 1.5
  ) + 
  ggplot2::geom_hline(
    size = 1.5,
    linetype = "dashed",
    ggplot2::aes(yintercept = summary(mod0)$coef[1])
  ) + 
  lecture_ggplot_theme_barplot + 
  ggplot2::labs(
    y = "Cluster Intercepts"
  )
```

## Calculating an ICC from the Unconditional Random-Intercept Model

```{r}
#| echo: false

within_cluster_var <- 1.137
btw_cluster_var <- .624
icc <- btw_cluster_var / (within_cluster_var + btw_cluster_var)
```

The ICC tells us that `r paste0(round(icc, 3)*100, "%")` of the total variance in psychological safety is due to differences between leaders. 

```{r}
#| eval: false
within_cluster_var <- 1.137
btw_cluster_var <- .624
icc <- btw_cluster_var / (within_cluster_var + btw_cluster_var)
```

```{r}
#| echo: false
round(icc, 3)
```

## Explaining Variance at Different Levels

A powerful aspect of the LMER model is that not only does it allow us to correct for violations of independence by separating within-cluster variance from between-cluster variance, it also lets us directly model the different variance components by including within-cluster predictors (level 1 predictors) and between-cluster predictors (level 2 predictors):

- Student SES (level 1) and classroom size (level 2) predicting student outcomes
- Employee attitudes (level 1) and leader behavior (level 2) predicting employee performance 
- Daily exercise (level 1) and age (level 2) predicting an individual's blood pressure

## The Conditional Random-Intecept Model

In our example, we have measured the employees' perceptions of their leader's inclusive behaviors, so we have a within-cluster or level 1 predictor: Employee perceptions of their team leader's inclusive behaviors. Now we want to know to what extent are an employee's perceptions of their leader's inclusive behaviors related to their individual perceptions of psychological safety.

```{r}
mod1 <- lmerTest::lmer(y_psych_safe ~ x_inc_lead + (1|team_id), data = data_ps)
```

## Understanding How Leader Inclusive Behavior Relates to Psychological Safety

This tells us that for every unit increase in an individual's perceptions of their leader's inclusive behaviors, we expect their psychological safety to increase by `r round(summary(mod1)$coef[2, 1], 2)` units. 

```{r}
summary(mod1)
```

## Interpreting the Coefficient Table

The things to note from the coefficient table are: 

1. The magnitude/sign of the estimated coefficient
2. The test statistic (`t value`)
3. The p-value (is the effect significant or not?)
4. The degrees of freedom: decimal value?? 

## Visualizing the Conditional Random-Intercept Model 

```{r}
#| echo: false

set.seed(5442)
samp_size <- 10
ranef_mod1 <- ranef(mod1)$team_id |> unlist() |> as.numeric()

ranef_mod1 <- sample(ranef_mod1, size = samp_size)

data_mod1 <- 
  tibble::tibble(
    ranef = summary(mod1)$coef[1, 1] + ranef_mod1,
    slope = summary(mod1)$coef[2, 1]
  ) |>
  dplyr::mutate(id = 1:samp_size)

data_fake <- 
  tibble::tibble(
    x = rep(1:11, samp_size),
    id = rep(1:samp_size, each = length(1:11))
  ) |>
  dplyr::left_join(
    data_mod1,
    dplyr::join_by(id)
  ) |>
  dplyr::mutate(
    y = ranef + slope*x
  )

ggplot2::ggplot(
  data = data_fake,
  ggplot2::aes(
    y = y,
    x= x
  )
) + 
  ggplot2::geom_point(
    shape = 21,
    fill = plot_fill,
    color = plot_color
  ) + 
  ggplot2::geom_abline(
    color = plot_fill,
    size = 1.25,
    ggplot2::aes(
      intercept = ranef,
      slope = slope
    )
  ) + 
  ggplot2::labs(
    x = "Perceived Inclusive Behaviors",
    y = "Predicted Psychological Safety"
  ) + 
  lecture_ggplot_theme_barplot
```


## Cluster-Level (Level 2) Predictors 

We can also add interesting cluster-level predictors like attitudes and personal traits about the leader that they themselves provide or we can aggregate level 1 predictors to create level 2 predictors. 

The important thing to remember is that cluster-level variables **vary across** clusters, but not within them. 

## Contextual Effects 

We want to know to what extent does the average team perception of a leader's inclusive behavior affect perceptions of psychological safety: The contextual effect of a leader's inclusive behavior. 

Contextual effects tell us to what extent two individual's with the same within-cluster predictor score, but a unit difference on the aggregated cluster-level predictor differ on the outcome variable. It is the extent to which the "context" of a cluster impacts the outcome above and beyond the within-cluster effect. 

## Creating a Contextual Effects

Contextual effects are created by taking the cluster average of a within-cluster predictor: 

```{r}
data_ps <- 
  data_ps |> 
  dplyr::group_by(
    team_id
  ) |>
  dplyr::mutate(
    x_inc_lead_gpm = mean(x_inc_lead, na.rm = TRUE)
  ) |>
  dplyr::ungroup()


mod2 <- lmerTest::lmer(y_psych_safe ~ x_inc_lead + x_inc_lead_gpm + (1|team_id),
                       data = data_ps)
```

## Interpreting the Contextual Effect 

We expect two individuals who have the same scores on their individual measures of inclusive behavior, but report to two different leaders who differ by one unit on the aggregate inclusive behavior measure to differ by `r round(summary(mod2)$coef[3, 1], 2)` units on their measure of psychological safety, on average. 

It is the additional effect that shared perceptions of a leader's inclusive behavior (or an aggregated within-cluster variable) have above their individual-level effect. 

## Interpreting the Contextual Effect

```{r}
#| echo: false
summary(mod2)
```

## What Happens If We Neglect Clusters? 

If we neglect to model between-cluster variance, then we run the risk of **underestimating** our standard errors which means we are more likely to commit a Type 1 Error: Declaring an effect significant when it is not.  

```{r}
#| echo: false
mod_lm <- lm(y_psych_safe ~ x_inc_lead + x_inc_lead_gpm, data_ps)

se_table <- 
  tibble::tibble(
    Effect = c("Intercept", "Ind. Inc. Beh.", "Cont. Inc. Beh."),
    `LM Est.` = round(mod_lm$coef, 3),
    `LMER Est.` = round(summary(mod2)$coef[, 1], 3),
    `LM SE` = round(summary(mod_lm)$coef[, 2], 3),
    `LMER SE` = round(summary(mod2)$coef[, 2], 3)
  )

knitr::kable(se_table)
```







